{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu will be used\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(str(device) + ' will be used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __number_sampler(max_digit=3):\n",
    "    digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    k = random.randint(1,max_digit)\n",
    "    string = ''.join(random.sample(digits,k))\n",
    "    if string[0] == '0':\n",
    "        return __number_sampler(max_digit=max_digit)\n",
    "    return string\n",
    "\n",
    "def __operator_sampler():\n",
    "    operators = ['+','-','/','*']\n",
    "    return random.choice(operators)\n",
    "\n",
    "def get_random_input(n_input=100, max_len_limit=20, max_digit=3):\n",
    "    ret = []\n",
    "    for i in range(n_input):\n",
    "        length = random.randint(1,max_len_limit)\n",
    "        length = length+1 if length%2==1 else length\n",
    "        length = max_len_limit # added for simplicity, later delete this line to make problem more complicated\n",
    "        s = ''\n",
    "        for j in range(length+1):\n",
    "            if j % 2 == 0:\n",
    "                s += __number_sampler(max_digit=max_digit)\n",
    "            else:\n",
    "                s += __operator_sampler()\n",
    "        ret.append(s)\n",
    "    return ret\n",
    "\n",
    "def __one_hot_encoding(alphabet, max_len):\n",
    "    x = np.zeros((len(alphabet),len(alphabet)),dtype=np.int32)\n",
    "    dict_ = {}\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i,i] = 1\n",
    "        dict_[alphabet[i]] = x[i]\n",
    "    return dict_\n",
    "\n",
    "def create_input_seq(alphabet, max_len, input_sequence):\n",
    "    alphabet2encod = __one_hot_encoding(alphabet, max_len)\n",
    "    ret = np.zeros((len(input_sequence),len(input_sequence[0]),len(alphabet)))\n",
    "    for j, inp in enumerate(input_sequence):\n",
    "        temp = np.zeros((len(inp),len(alphabet)))\n",
    "        for i in range(temp.shape[0]):\n",
    "            temp[i,:] = alphabet2encod[inp[i]]\n",
    "        ret[j,:,:] = temp\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_feature_num, hidden_feature_num=20, n_layers=1, out_dim=1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.input_feature_num = input_feature_num\n",
    "        self.hidden_feature_num = hidden_feature_num\n",
    "        self.n_layers = n_layers\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.rnn = nn.RNN(input_feature_num, hidden_feature_num, n_layers)\n",
    "        self.fc = nn.Linear(hidden_feature_num, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_feature_num)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        hidden = hidden.squeeze(0)\n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_len = 4\n",
    "n_input = 10000\n",
    "alphabet = ['0','1','2','3','4','5','6','7','8','9','-','+','/','*'] \n",
    "target_values = []\n",
    "input_feature_num = len(alphabet)\n",
    "\n",
    "input_sequence = get_random_input(n_input=n_input, max_len_limit=max_len, max_digit=1)\n",
    "one_hot_input = create_input_seq(alphabet, max_len, input_sequence)\n",
    "input_seq = torch.FloatTensor(one_hot_input).permute(1,0,2)\n",
    "\n",
    "for i in range(len(input_sequence)):\n",
    "    target_values.append(eval(input_sequence[i]))\n",
    "\n",
    "target_values = torch.FloatTensor(target_values).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(input_feature_num=input_feature_num)\n",
    "model.to(device)\n",
    "\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 2646323.7500\n",
      "Epoch: 20/100............. Loss: 2646051.5000\n",
      "Epoch: 30/100............. Loss: 2645785.7500\n",
      "Epoch: 40/100............. Loss: 2645535.7500\n",
      "Epoch: 50/100............. Loss: 2645302.7500\n",
      "Epoch: 60/100............. Loss: 2645086.0000\n",
      "Epoch: 70/100............. Loss: 2644884.7500\n",
      "Epoch: 80/100............. Loss: 2644697.5000\n",
      "Epoch: 90/100............. Loss: 2644523.2500\n",
      "Epoch: 100/100............. Loss: 2644361.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,n_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    input_seq.to(device)\n",
    "    output = model(input_seq)\n",
    "    loss = loss_fn(output, target_values)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
