{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "from input_generator import get_input, __create_one_hot_seq\n",
    "from model import RNNModel\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda will be used\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(str(device) + ' will be used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_limit = 15 # must be an odd number\n",
    "n_input = 10000\n",
    "alphabet = ['0','1','2','3','4','5','6','7','8','9','-','+','/','*',' '] \n",
    "\n",
    "input_feature_num = len(alphabet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (rnn): RNN(15, 100)\n",
       "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(input_feature_num=input_feature_num, device=device)\n",
    "# add teh model path to the string if you want to load a model\n",
    "# model.load_state_dict(torch.load('/home/sadullah/calculator/model_logs/##'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "lr=0.005\n",
    "\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10000............. Loss: 35.0940\n",
      "Epoch: 20/10000............. Loss: 35.0854\n",
      "Epoch: 30/10000............. Loss: 35.0863\n",
      "Epoch: 40/10000............. Loss: 35.0864\n",
      "Epoch: 50/10000............. Loss: 35.0860\n",
      "Epoch: 60/10000............. Loss: 35.0856\n",
      "Epoch: 70/10000............. Loss: 35.0854\n",
      "Epoch: 80/10000............. Loss: 35.0851\n",
      "Epoch: 90/10000............. Loss: 35.0814\n",
      "Epoch: 100/10000............. Loss: 34.7592\n",
      "Epoch: 110/10000............. Loss: 34.1766\n",
      "Epoch: 120/10000............. Loss: 33.9140\n",
      "Epoch: 130/10000............. Loss: 33.6812\n",
      "Epoch: 140/10000............. Loss: 33.5550\n",
      "Epoch: 150/10000............. Loss: 33.4730\n",
      "Epoch: 160/10000............. Loss: 33.6724\n",
      "Epoch: 170/10000............. Loss: 33.4562\n",
      "Epoch: 180/10000............. Loss: 33.4318\n",
      "Epoch: 190/10000............. Loss: 33.5025\n",
      "Epoch: 200/10000............. Loss: 33.1859\n",
      "Epoch: 210/10000............. Loss: 32.9749\n",
      "Epoch: 220/10000............. Loss: 33.5153\n",
      "Epoch: 230/10000............. Loss: 33.6873\n",
      "Epoch: 240/10000............. Loss: 33.5493\n",
      "Epoch: 250/10000............. Loss: 33.0588\n",
      "Epoch: 260/10000............. Loss: 32.5249\n",
      "Epoch: 270/10000............. Loss: 32.4033\n",
      "Epoch: 280/10000............. Loss: 32.1554\n",
      "Epoch: 290/10000............. Loss: 32.4193\n",
      "Epoch: 300/10000............. Loss: 31.7856\n",
      "Epoch: 310/10000............. Loss: 31.4633\n",
      "Epoch: 320/10000............. Loss: 31.1982\n",
      "Epoch: 330/10000............. Loss: 31.0276\n",
      "Epoch: 340/10000............. Loss: 31.0043\n",
      "Epoch: 350/10000............. Loss: 31.0835\n",
      "Epoch: 360/10000............. Loss: 30.2720\n",
      "Epoch: 370/10000............. Loss: 29.9183\n",
      "Epoch: 380/10000............. Loss: 30.6085\n",
      "Epoch: 390/10000............. Loss: 29.7355\n",
      "Epoch: 400/10000............. Loss: 29.4221\n",
      "Epoch: 410/10000............. Loss: 28.9510\n",
      "Epoch: 420/10000............. Loss: 29.2196\n",
      "Epoch: 430/10000............. Loss: 28.3829\n",
      "Epoch: 440/10000............. Loss: 28.1278\n",
      "Epoch: 450/10000............. Loss: 28.3311\n",
      "Epoch: 460/10000............. Loss: 27.4217\n",
      "Epoch: 470/10000............. Loss: 27.3192\n",
      "Epoch: 480/10000............. Loss: 27.6908\n",
      "Epoch: 490/10000............. Loss: 26.6381\n",
      "Epoch: 500/10000............. Loss: 26.7127\n",
      "Epoch: 510/10000............. Loss: 26.1742\n",
      "Epoch: 520/10000............. Loss: 26.1812\n",
      "Epoch: 530/10000............. Loss: 25.9545\n",
      "Epoch: 540/10000............. Loss: 25.7297\n",
      "Epoch: 550/10000............. Loss: 25.2838\n",
      "Epoch: 560/10000............. Loss: 25.2539\n",
      "Epoch: 570/10000............. Loss: 25.2062\n",
      "Epoch: 580/10000............. Loss: 24.6878\n",
      "Epoch: 590/10000............. Loss: 25.4493\n",
      "Epoch: 600/10000............. Loss: 25.0678\n",
      "Epoch: 610/10000............. Loss: 24.4222\n",
      "Epoch: 620/10000............. Loss: 25.2854\n",
      "Epoch: 630/10000............. Loss: 24.0140\n",
      "Epoch: 640/10000............. Loss: 24.2623\n",
      "Epoch: 650/10000............. Loss: 23.9520\n",
      "Epoch: 660/10000............. Loss: 23.8608\n",
      "Epoch: 670/10000............. Loss: 23.4094\n",
      "Epoch: 680/10000............. Loss: 23.5272\n",
      "Epoch: 690/10000............. Loss: 23.5762\n",
      "Epoch: 700/10000............. Loss: 24.0182\n",
      "Epoch: 710/10000............. Loss: 23.4618\n",
      "Epoch: 720/10000............. Loss: 23.9024\n",
      "Epoch: 730/10000............. Loss: 23.0968\n",
      "Epoch: 740/10000............. Loss: 23.4364\n",
      "Epoch: 750/10000............. Loss: 23.1064\n",
      "Epoch: 760/10000............. Loss: 23.2786\n",
      "Epoch: 770/10000............. Loss: 23.1144\n",
      "Epoch: 780/10000............. Loss: 24.1829\n",
      "Epoch: 790/10000............. Loss: 22.5812\n",
      "Epoch: 800/10000............. Loss: 22.5937\n",
      "Epoch: 810/10000............. Loss: 22.6701\n",
      "Epoch: 820/10000............. Loss: 22.2706\n",
      "Epoch: 830/10000............. Loss: 22.5665\n",
      "Epoch: 840/10000............. Loss: 22.3650\n",
      "Epoch: 850/10000............. Loss: 23.0634\n",
      "Epoch: 860/10000............. Loss: 23.3043\n",
      "Epoch: 870/10000............. Loss: 23.1467\n",
      "Epoch: 880/10000............. Loss: 22.1895\n",
      "Epoch: 890/10000............. Loss: 23.1908\n",
      "Epoch: 900/10000............. Loss: 22.0915\n",
      "Epoch: 910/10000............. Loss: 21.9077\n",
      "Epoch: 920/10000............. Loss: 21.9839\n",
      "Epoch: 930/10000............. Loss: 21.9968\n",
      "Epoch: 940/10000............. Loss: 23.6167\n",
      "Epoch: 950/10000............. Loss: 22.2585\n",
      "Epoch: 960/10000............. Loss: 21.8824\n",
      "Epoch: 970/10000............. Loss: 22.1655\n",
      "Epoch: 980/10000............. Loss: 21.8926\n",
      "Epoch: 990/10000............. Loss: 21.6587\n",
      "Epoch: 1000/10000............. Loss: 44.8842\n",
      "Epoch: 1010/10000............. Loss: 43.9365\n",
      "Epoch: 1020/10000............. Loss: 43.7954\n",
      "Epoch: 1030/10000............. Loss: 43.6684\n",
      "Epoch: 1040/10000............. Loss: 43.4935\n",
      "Epoch: 1050/10000............. Loss: 43.9776\n",
      "Epoch: 1060/10000............. Loss: 43.8889\n",
      "Epoch: 1070/10000............. Loss: 43.3846\n",
      "Epoch: 1080/10000............. Loss: 43.8726\n",
      "Epoch: 1090/10000............. Loss: 43.5384\n",
      "Epoch: 1100/10000............. Loss: 43.7059\n",
      "Epoch: 1110/10000............. Loss: 44.5479\n",
      "Epoch: 1120/10000............. Loss: 44.7361\n",
      "Epoch: 1130/10000............. Loss: 43.3894\n",
      "Epoch: 1140/10000............. Loss: 43.1232\n",
      "Epoch: 1150/10000............. Loss: 44.7432\n",
      "Epoch: 1160/10000............. Loss: 43.2919\n",
      "Epoch: 1170/10000............. Loss: 42.9954\n",
      "Epoch: 1180/10000............. Loss: 43.2679\n",
      "Epoch: 1190/10000............. Loss: 42.6697\n",
      "Epoch: 1200/10000............. Loss: 42.6914\n",
      "Epoch: 1210/10000............. Loss: 42.7018\n",
      "Epoch: 1220/10000............. Loss: 43.8998\n",
      "Epoch: 1230/10000............. Loss: 42.6856\n",
      "Epoch: 1240/10000............. Loss: 42.8876\n",
      "Epoch: 1250/10000............. Loss: 43.3265\n",
      "Epoch: 1260/10000............. Loss: 43.1083\n",
      "Epoch: 1270/10000............. Loss: 42.4252\n",
      "Epoch: 1280/10000............. Loss: 42.6620\n",
      "Epoch: 1290/10000............. Loss: 42.7426\n",
      "Epoch: 1300/10000............. Loss: 42.6078\n",
      "Epoch: 1310/10000............. Loss: 42.9571\n",
      "Epoch: 1320/10000............. Loss: 42.7892\n",
      "Epoch: 1330/10000............. Loss: 42.7699\n",
      "Epoch: 1340/10000............. Loss: 42.6667\n",
      "Epoch: 1350/10000............. Loss: 42.7706\n",
      "Epoch: 1360/10000............. Loss: 42.4556\n",
      "Epoch: 1370/10000............. Loss: 42.6062\n",
      "Epoch: 1380/10000............. Loss: 42.4644\n",
      "Epoch: 1390/10000............. Loss: 42.4247\n",
      "Epoch: 1400/10000............. Loss: 42.2892\n",
      "Epoch: 1410/10000............. Loss: 42.2626\n",
      "Epoch: 1420/10000............. Loss: 42.0960\n",
      "Epoch: 1430/10000............. Loss: 42.7880\n",
      "Epoch: 1440/10000............. Loss: 42.7730\n",
      "Epoch: 1450/10000............. Loss: 42.4772\n",
      "Epoch: 1460/10000............. Loss: 42.2827\n",
      "Epoch: 1470/10000............. Loss: 42.0747\n",
      "Epoch: 1480/10000............. Loss: 42.3994\n",
      "Epoch: 1490/10000............. Loss: 41.7555\n",
      "Epoch: 1500/10000............. Loss: 41.7232\n",
      "Epoch: 1510/10000............. Loss: 42.1000\n",
      "Epoch: 1520/10000............. Loss: 42.2416\n",
      "Epoch: 1530/10000............. Loss: 41.9708\n",
      "Epoch: 1540/10000............. Loss: 41.9612\n",
      "Epoch: 1550/10000............. Loss: 41.9041\n",
      "Epoch: 1560/10000............. Loss: 42.2362\n",
      "Epoch: 1570/10000............. Loss: 42.2082\n",
      "Epoch: 1580/10000............. Loss: 42.0300\n",
      "Epoch: 1590/10000............. Loss: 41.7899\n",
      "Epoch: 1600/10000............. Loss: 42.5956\n",
      "Epoch: 1610/10000............. Loss: 41.8919\n",
      "Epoch: 1620/10000............. Loss: 41.6707\n",
      "Epoch: 1630/10000............. Loss: 42.1928\n",
      "Epoch: 1640/10000............. Loss: 41.6174\n",
      "Epoch: 1650/10000............. Loss: 41.8342\n",
      "Epoch: 1660/10000............. Loss: 41.7459\n",
      "Epoch: 1670/10000............. Loss: 41.6007\n",
      "Epoch: 1680/10000............. Loss: 41.7408\n",
      "Epoch: 1690/10000............. Loss: 41.4422\n",
      "Epoch: 1700/10000............. Loss: 41.4057\n",
      "Epoch: 1710/10000............. Loss: 41.5897\n",
      "Epoch: 1720/10000............. Loss: 41.5714\n",
      "Epoch: 1730/10000............. Loss: 41.2245\n",
      "Epoch: 1740/10000............. Loss: 41.4722\n",
      "Epoch: 1750/10000............. Loss: 41.4575\n",
      "Epoch: 1760/10000............. Loss: 41.1593\n",
      "Epoch: 1770/10000............. Loss: 41.8265\n",
      "Epoch: 1780/10000............. Loss: 41.2044\n",
      "Epoch: 1790/10000............. Loss: 41.9940\n",
      "Epoch: 1800/10000............. Loss: 42.3857\n",
      "Epoch: 1810/10000............. Loss: 41.2954\n",
      "Epoch: 1820/10000............. Loss: 41.5116\n",
      "Epoch: 1830/10000............. Loss: 41.8828\n",
      "Epoch: 1840/10000............. Loss: 41.3498\n",
      "Epoch: 1850/10000............. Loss: 41.2417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1860/10000............. Loss: 41.8812\n",
      "Epoch: 1870/10000............. Loss: 41.9964\n",
      "Epoch: 1880/10000............. Loss: 41.2279\n",
      "Epoch: 1890/10000............. Loss: 41.0494\n",
      "Epoch: 1900/10000............. Loss: 42.9373\n",
      "Epoch: 1910/10000............. Loss: 41.6838\n",
      "Epoch: 1920/10000............. Loss: 41.1816\n",
      "Epoch: 1930/10000............. Loss: 41.2501\n",
      "Epoch: 1940/10000............. Loss: 40.9350\n",
      "Epoch: 1950/10000............. Loss: 40.8435\n",
      "Epoch: 1960/10000............. Loss: 40.9127\n",
      "Epoch: 1970/10000............. Loss: 41.0871\n",
      "Epoch: 1980/10000............. Loss: 41.3619\n",
      "Epoch: 1990/10000............. Loss: 42.2572\n",
      "Epoch: 2000/10000............. Loss: 21.5260\n",
      "Epoch: 2010/10000............. Loss: 20.8962\n",
      "Epoch: 2020/10000............. Loss: 20.8547\n",
      "Epoch: 2030/10000............. Loss: 20.6179\n",
      "Epoch: 2040/10000............. Loss: 20.5643\n",
      "Epoch: 2050/10000............. Loss: 20.6216\n",
      "Epoch: 2060/10000............. Loss: 20.9693\n",
      "Epoch: 2070/10000............. Loss: 20.6886\n",
      "Epoch: 2080/10000............. Loss: 20.4675\n",
      "Epoch: 2090/10000............. Loss: 20.5285\n",
      "Epoch: 2100/10000............. Loss: 20.4497\n",
      "Epoch: 2110/10000............. Loss: 20.3316\n",
      "Epoch: 2120/10000............. Loss: 20.6899\n",
      "Epoch: 2130/10000............. Loss: 20.5276\n",
      "Epoch: 2140/10000............. Loss: 20.5118\n",
      "Epoch: 2150/10000............. Loss: 20.5602\n",
      "Epoch: 2160/10000............. Loss: 21.3397\n",
      "Epoch: 2170/10000............. Loss: 20.8579\n",
      "Epoch: 2180/10000............. Loss: 20.6600\n",
      "Epoch: 2190/10000............. Loss: 20.3263\n",
      "Epoch: 2200/10000............. Loss: 20.2961\n",
      "Epoch: 2210/10000............. Loss: 20.5083\n",
      "Epoch: 2220/10000............. Loss: 20.3274\n",
      "Epoch: 2230/10000............. Loss: 20.6054\n",
      "Epoch: 2240/10000............. Loss: 20.3679\n",
      "Epoch: 2250/10000............. Loss: 20.6879\n",
      "Epoch: 2260/10000............. Loss: 20.3009\n",
      "Epoch: 2270/10000............. Loss: 20.3768\n",
      "Epoch: 2280/10000............. Loss: 20.4788\n",
      "Epoch: 2290/10000............. Loss: 20.8581\n",
      "Epoch: 2300/10000............. Loss: 20.3113\n",
      "Epoch: 2310/10000............. Loss: 20.1811\n",
      "Epoch: 2320/10000............. Loss: 20.3205\n",
      "Epoch: 2330/10000............. Loss: 20.1755\n",
      "Epoch: 2340/10000............. Loss: 21.8087\n",
      "Epoch: 2350/10000............. Loss: 20.9013\n",
      "Epoch: 2360/10000............. Loss: 20.5564\n",
      "Epoch: 2370/10000............. Loss: 20.6513\n",
      "Epoch: 2380/10000............. Loss: 20.0216\n",
      "Epoch: 2390/10000............. Loss: 19.8192\n",
      "Epoch: 2400/10000............. Loss: 21.0335\n",
      "Epoch: 2410/10000............. Loss: 20.7247\n",
      "Epoch: 2420/10000............. Loss: 20.3740\n",
      "Epoch: 2430/10000............. Loss: 20.0309\n",
      "Epoch: 2440/10000............. Loss: 19.8012\n",
      "Epoch: 2450/10000............. Loss: 20.8608\n",
      "Epoch: 2460/10000............. Loss: 19.9619\n",
      "Epoch: 2470/10000............. Loss: 19.9746\n",
      "Epoch: 2480/10000............. Loss: 19.9975\n",
      "Epoch: 2490/10000............. Loss: 19.8024\n",
      "Epoch: 2500/10000............. Loss: 20.0014\n",
      "Epoch: 2510/10000............. Loss: 19.8510\n",
      "Epoch: 2520/10000............. Loss: 19.6940\n",
      "Epoch: 2530/10000............. Loss: 19.7650\n",
      "Epoch: 2540/10000............. Loss: 19.8977\n",
      "Epoch: 2550/10000............. Loss: 19.7364\n",
      "Epoch: 2560/10000............. Loss: 19.5537\n",
      "Epoch: 2570/10000............. Loss: 19.8752\n",
      "Epoch: 2580/10000............. Loss: 19.7241\n",
      "Epoch: 2590/10000............. Loss: 19.8008\n",
      "Epoch: 2600/10000............. Loss: 19.5296\n",
      "Epoch: 2610/10000............. Loss: 19.9736\n",
      "Epoch: 2620/10000............. Loss: 19.9012\n",
      "Epoch: 2630/10000............. Loss: 20.1105\n",
      "Epoch: 2640/10000............. Loss: 19.7760\n",
      "Epoch: 2650/10000............. Loss: 19.9761\n",
      "Epoch: 2660/10000............. Loss: 19.5287\n",
      "Epoch: 2670/10000............. Loss: 20.0905\n",
      "Epoch: 2680/10000............. Loss: 20.0271\n",
      "Epoch: 2690/10000............. Loss: 19.6593\n",
      "Epoch: 2700/10000............. Loss: 19.4035\n",
      "Epoch: 2710/10000............. Loss: 20.2611\n",
      "Epoch: 2720/10000............. Loss: 19.7417\n",
      "Epoch: 2730/10000............. Loss: 19.5275\n",
      "Epoch: 2740/10000............. Loss: 19.6765\n",
      "Epoch: 2750/10000............. Loss: 19.6631\n",
      "Epoch: 2760/10000............. Loss: 19.3964\n",
      "Epoch: 2770/10000............. Loss: 19.3478\n",
      "Epoch: 2780/10000............. Loss: 19.5421\n",
      "Epoch: 2790/10000............. Loss: 21.1046\n",
      "Epoch: 2800/10000............. Loss: 19.9773\n",
      "Epoch: 2810/10000............. Loss: 19.4878\n",
      "Epoch: 2820/10000............. Loss: 19.8107\n",
      "Epoch: 2830/10000............. Loss: 19.6072\n",
      "Epoch: 2840/10000............. Loss: 20.0216\n",
      "Epoch: 2850/10000............. Loss: 20.0599\n",
      "Epoch: 2860/10000............. Loss: 19.6490\n",
      "Epoch: 2870/10000............. Loss: 19.2859\n",
      "Epoch: 2880/10000............. Loss: 19.6097\n",
      "Epoch: 2890/10000............. Loss: 19.3885\n",
      "Epoch: 2900/10000............. Loss: 19.2190\n",
      "Epoch: 2910/10000............. Loss: 19.1691\n",
      "Epoch: 2920/10000............. Loss: 19.9058\n",
      "Epoch: 2930/10000............. Loss: 19.5192\n",
      "Epoch: 2940/10000............. Loss: 19.2889\n",
      "Epoch: 2950/10000............. Loss: 19.3531\n",
      "Epoch: 2960/10000............. Loss: 19.3618\n",
      "Epoch: 2970/10000............. Loss: 19.4856\n",
      "Epoch: 2980/10000............. Loss: 19.2535\n",
      "Epoch: 2990/10000............. Loss: 19.3517\n",
      "Epoch: 3000/10000............. Loss: 27.7490\n",
      "Epoch: 3010/10000............. Loss: 27.5584\n",
      "Epoch: 3020/10000............. Loss: 27.4098\n",
      "Epoch: 3030/10000............. Loss: 27.3736\n",
      "Epoch: 3040/10000............. Loss: 27.3583\n",
      "Epoch: 3050/10000............. Loss: 27.7680\n",
      "Epoch: 3060/10000............. Loss: 28.3920\n",
      "Epoch: 3070/10000............. Loss: 27.3780\n",
      "Epoch: 3080/10000............. Loss: 27.3883\n",
      "Epoch: 3090/10000............. Loss: 27.6307\n",
      "Epoch: 3100/10000............. Loss: 27.0994\n",
      "Epoch: 3110/10000............. Loss: 28.1416\n",
      "Epoch: 3120/10000............. Loss: 27.4577\n",
      "Epoch: 3130/10000............. Loss: 28.1067\n",
      "Epoch: 3140/10000............. Loss: 27.2196\n",
      "Epoch: 3150/10000............. Loss: 27.2889\n",
      "Epoch: 3160/10000............. Loss: 28.2319\n",
      "Epoch: 3170/10000............. Loss: 27.9506\n",
      "Epoch: 3180/10000............. Loss: 27.4232\n",
      "Epoch: 3190/10000............. Loss: 27.8755\n",
      "Epoch: 3200/10000............. Loss: 27.1644\n",
      "Epoch: 3210/10000............. Loss: 27.0205\n",
      "Epoch: 3220/10000............. Loss: 28.1064\n",
      "Epoch: 3230/10000............. Loss: 27.0527\n",
      "Epoch: 3240/10000............. Loss: 27.0759\n",
      "Epoch: 3250/10000............. Loss: 26.9275\n",
      "Epoch: 3260/10000............. Loss: 27.1405\n",
      "Epoch: 3270/10000............. Loss: 26.8180\n",
      "Epoch: 3280/10000............. Loss: 27.8838\n",
      "Epoch: 3290/10000............. Loss: 27.9300\n",
      "Epoch: 3300/10000............. Loss: 27.1044\n",
      "Epoch: 3310/10000............. Loss: 26.9249\n",
      "Epoch: 3320/10000............. Loss: 27.3086\n",
      "Epoch: 3330/10000............. Loss: 28.1255\n",
      "Epoch: 3340/10000............. Loss: 27.5836\n",
      "Epoch: 3350/10000............. Loss: 26.9873\n",
      "Epoch: 3360/10000............. Loss: 27.2060\n",
      "Epoch: 3370/10000............. Loss: 26.7680\n",
      "Epoch: 3380/10000............. Loss: 26.9969\n",
      "Epoch: 3390/10000............. Loss: 26.6735\n",
      "Epoch: 3400/10000............. Loss: 28.0330\n",
      "Epoch: 3410/10000............. Loss: 27.0262\n",
      "Epoch: 3420/10000............. Loss: 27.2839\n",
      "Epoch: 3430/10000............. Loss: 27.0303\n",
      "Epoch: 3440/10000............. Loss: 27.1166\n",
      "Epoch: 3450/10000............. Loss: 26.7779\n",
      "Epoch: 3460/10000............. Loss: 26.7234\n",
      "Epoch: 3470/10000............. Loss: 26.6997\n",
      "Epoch: 3480/10000............. Loss: 26.9699\n",
      "Epoch: 3490/10000............. Loss: 27.3410\n",
      "Epoch: 3500/10000............. Loss: 26.6864\n",
      "Epoch: 3510/10000............. Loss: 27.0275\n",
      "Epoch: 3520/10000............. Loss: 26.9647\n",
      "Epoch: 3530/10000............. Loss: 26.6342\n",
      "Epoch: 3540/10000............. Loss: 26.4988\n",
      "Epoch: 3550/10000............. Loss: 27.3443\n",
      "Epoch: 3560/10000............. Loss: 26.8889\n",
      "Epoch: 3570/10000............. Loss: 26.5952\n",
      "Epoch: 3580/10000............. Loss: 26.4692\n",
      "Epoch: 3590/10000............. Loss: 26.4587\n",
      "Epoch: 3600/10000............. Loss: 26.7492\n",
      "Epoch: 3610/10000............. Loss: 26.3734\n",
      "Epoch: 3620/10000............. Loss: 26.5139\n",
      "Epoch: 3630/10000............. Loss: 26.4450\n",
      "Epoch: 3640/10000............. Loss: 26.7696\n",
      "Epoch: 3650/10000............. Loss: 27.3883\n",
      "Epoch: 3660/10000............. Loss: 26.5246\n",
      "Epoch: 3670/10000............. Loss: 26.7330\n",
      "Epoch: 3680/10000............. Loss: 26.3897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3690/10000............. Loss: 26.3342\n",
      "Epoch: 3700/10000............. Loss: 26.3742\n",
      "Epoch: 3710/10000............. Loss: 26.7260\n",
      "Epoch: 3720/10000............. Loss: 26.9485\n",
      "Epoch: 3730/10000............. Loss: 27.0210\n",
      "Epoch: 3740/10000............. Loss: 26.4613\n",
      "Epoch: 3750/10000............. Loss: 26.2565\n",
      "Epoch: 3760/10000............. Loss: 26.2669\n",
      "Epoch: 3770/10000............. Loss: 26.4885\n",
      "Epoch: 3780/10000............. Loss: 26.2819\n",
      "Epoch: 3790/10000............. Loss: 27.2341\n",
      "Epoch: 3800/10000............. Loss: 26.6472\n",
      "Epoch: 3810/10000............. Loss: 26.8001\n",
      "Epoch: 3820/10000............. Loss: 26.5928\n",
      "Epoch: 3830/10000............. Loss: 26.4628\n",
      "Epoch: 3840/10000............. Loss: 26.5930\n",
      "Epoch: 3850/10000............. Loss: 26.3141\n",
      "Epoch: 3860/10000............. Loss: 26.3537\n",
      "Epoch: 3870/10000............. Loss: 26.3102\n",
      "Epoch: 3880/10000............. Loss: 26.8651\n",
      "Epoch: 3890/10000............. Loss: 26.1188\n",
      "Epoch: 3900/10000............. Loss: 26.2356\n",
      "Epoch: 3910/10000............. Loss: 26.1152\n",
      "Epoch: 3920/10000............. Loss: 26.1389\n",
      "Epoch: 3930/10000............. Loss: 26.7225\n",
      "Epoch: 3940/10000............. Loss: 26.8300\n",
      "Epoch: 3950/10000............. Loss: 26.2874\n",
      "Epoch: 3960/10000............. Loss: 26.1026\n",
      "Epoch: 3970/10000............. Loss: 26.2200\n",
      "Epoch: 3980/10000............. Loss: 26.6604\n",
      "Epoch: 3990/10000............. Loss: 26.1812\n",
      "Epoch: 4000/10000............. Loss: 27.3679\n",
      "Epoch: 4010/10000............. Loss: 26.8121\n",
      "Epoch: 4020/10000............. Loss: 26.3974\n",
      "Epoch: 4030/10000............. Loss: 26.1869\n",
      "Epoch: 4040/10000............. Loss: 26.2241\n",
      "Epoch: 4050/10000............. Loss: 26.3801\n",
      "Epoch: 4060/10000............. Loss: 26.2489\n",
      "Epoch: 4070/10000............. Loss: 26.4489\n",
      "Epoch: 4080/10000............. Loss: 25.9380\n",
      "Epoch: 4090/10000............. Loss: 26.3463\n",
      "Epoch: 4100/10000............. Loss: 26.0886\n",
      "Epoch: 4110/10000............. Loss: 26.1864\n",
      "Epoch: 4120/10000............. Loss: 25.8860\n",
      "Epoch: 4130/10000............. Loss: 25.9334\n",
      "Epoch: 4140/10000............. Loss: 26.2868\n",
      "Epoch: 4150/10000............. Loss: 26.0603\n",
      "Epoch: 4160/10000............. Loss: 25.9419\n",
      "Epoch: 4170/10000............. Loss: 26.4548\n",
      "Epoch: 4180/10000............. Loss: 26.3085\n",
      "Epoch: 4190/10000............. Loss: 25.8531\n",
      "Epoch: 4200/10000............. Loss: 26.4536\n",
      "Epoch: 4210/10000............. Loss: 25.9087\n",
      "Epoch: 4220/10000............. Loss: 26.7551\n",
      "Epoch: 4230/10000............. Loss: 26.4992\n",
      "Epoch: 4240/10000............. Loss: 26.5532\n",
      "Epoch: 4250/10000............. Loss: 26.0485\n",
      "Epoch: 4260/10000............. Loss: 26.1655\n",
      "Epoch: 4270/10000............. Loss: 26.1397\n",
      "Epoch: 4280/10000............. Loss: 25.7175\n",
      "Epoch: 4290/10000............. Loss: 25.7818\n",
      "Epoch: 4300/10000............. Loss: 25.9138\n",
      "Epoch: 4310/10000............. Loss: 25.9261\n",
      "Epoch: 4320/10000............. Loss: 25.9349\n",
      "Epoch: 4330/10000............. Loss: 25.7205\n",
      "Epoch: 4340/10000............. Loss: 25.8416\n",
      "Epoch: 4350/10000............. Loss: 25.7081\n",
      "Epoch: 4360/10000............. Loss: 26.0888\n",
      "Epoch: 4370/10000............. Loss: 25.8408\n",
      "Epoch: 4380/10000............. Loss: 25.9695\n",
      "Epoch: 4390/10000............. Loss: 25.7072\n",
      "Epoch: 4400/10000............. Loss: 25.6291\n",
      "Epoch: 4410/10000............. Loss: 27.2353\n",
      "Epoch: 4420/10000............. Loss: 26.0717\n",
      "Epoch: 4430/10000............. Loss: 25.9661\n",
      "Epoch: 4440/10000............. Loss: 25.8480\n",
      "Epoch: 4450/10000............. Loss: 26.1696\n",
      "Epoch: 4460/10000............. Loss: 26.1079\n",
      "Epoch: 4470/10000............. Loss: 25.8586\n",
      "Epoch: 4480/10000............. Loss: 25.9977\n",
      "Epoch: 4490/10000............. Loss: 25.9533\n",
      "Epoch: 4500/10000............. Loss: 25.9060\n",
      "Epoch: 4510/10000............. Loss: 25.7340\n",
      "Epoch: 4520/10000............. Loss: 25.8850\n",
      "Epoch: 4530/10000............. Loss: 25.8793\n",
      "Epoch: 4540/10000............. Loss: 25.8261\n",
      "Epoch: 4550/10000............. Loss: 25.6426\n",
      "Epoch: 4560/10000............. Loss: 25.6694\n",
      "Epoch: 4570/10000............. Loss: 25.4356\n",
      "Epoch: 4580/10000............. Loss: 26.1353\n",
      "Epoch: 4590/10000............. Loss: 25.6091\n",
      "Epoch: 4600/10000............. Loss: 25.9548\n",
      "Epoch: 4610/10000............. Loss: 25.4572\n",
      "Epoch: 4620/10000............. Loss: 25.8855\n",
      "Epoch: 4630/10000............. Loss: 26.0740\n",
      "Epoch: 4640/10000............. Loss: 27.3641\n",
      "Epoch: 4650/10000............. Loss: 25.8421\n",
      "Epoch: 4660/10000............. Loss: 25.6318\n",
      "Epoch: 4670/10000............. Loss: 25.3210\n",
      "Epoch: 4680/10000............. Loss: 25.8485\n",
      "Epoch: 4690/10000............. Loss: 25.6984\n",
      "Epoch: 4700/10000............. Loss: 25.6132\n",
      "Epoch: 4710/10000............. Loss: 25.5798\n",
      "Epoch: 4720/10000............. Loss: 25.4048\n",
      "Epoch: 4730/10000............. Loss: 25.3640\n",
      "Epoch: 4740/10000............. Loss: 25.7402\n",
      "Epoch: 4750/10000............. Loss: 25.3367\n",
      "Epoch: 4760/10000............. Loss: 25.3832\n",
      "Epoch: 4770/10000............. Loss: 25.6871\n",
      "Epoch: 4780/10000............. Loss: 25.5224\n",
      "Epoch: 4790/10000............. Loss: 25.8373\n",
      "Epoch: 4800/10000............. Loss: 25.7672\n",
      "Epoch: 4810/10000............. Loss: 25.2542\n",
      "Epoch: 4820/10000............. Loss: 25.5062\n",
      "Epoch: 4830/10000............. Loss: 25.8069\n",
      "Epoch: 4840/10000............. Loss: 25.8028\n",
      "Epoch: 4850/10000............. Loss: 25.6626\n",
      "Epoch: 4860/10000............. Loss: 25.4585\n",
      "Epoch: 4870/10000............. Loss: 25.2961\n",
      "Epoch: 4880/10000............. Loss: 25.7156\n",
      "Epoch: 4890/10000............. Loss: 25.5356\n",
      "Epoch: 4900/10000............. Loss: 25.4479\n",
      "Epoch: 4910/10000............. Loss: 25.6577\n",
      "Epoch: 4920/10000............. Loss: 25.5224\n",
      "Epoch: 4930/10000............. Loss: 25.4955\n",
      "Epoch: 4940/10000............. Loss: 25.5870\n",
      "Epoch: 4950/10000............. Loss: 25.0968\n",
      "Epoch: 4960/10000............. Loss: 25.2892\n",
      "Epoch: 4970/10000............. Loss: 25.8431\n",
      "Epoch: 4980/10000............. Loss: 25.1669\n",
      "Epoch: 4990/10000............. Loss: 25.4040\n",
      "Epoch: 5000/10000............. Loss: 24.2685\n",
      "Epoch: 5010/10000............. Loss: 24.0354\n",
      "Epoch: 5020/10000............. Loss: 24.0699\n",
      "Epoch: 5030/10000............. Loss: 23.8242\n",
      "Epoch: 5040/10000............. Loss: 23.9742\n",
      "Epoch: 5050/10000............. Loss: 23.9463\n",
      "Epoch: 5060/10000............. Loss: 24.0108\n",
      "Epoch: 5070/10000............. Loss: 23.8192\n",
      "Epoch: 5080/10000............. Loss: 23.7746\n",
      "Epoch: 5090/10000............. Loss: 24.0041\n",
      "Epoch: 5100/10000............. Loss: 24.2791\n",
      "Epoch: 5110/10000............. Loss: 25.7751\n",
      "Epoch: 5120/10000............. Loss: 24.3187\n",
      "Epoch: 5130/10000............. Loss: 24.1038\n",
      "Epoch: 5140/10000............. Loss: 23.8194\n",
      "Epoch: 5150/10000............. Loss: 23.8036\n",
      "Epoch: 5160/10000............. Loss: 23.6387\n",
      "Epoch: 5170/10000............. Loss: 24.0368\n",
      "Epoch: 5180/10000............. Loss: 24.6937\n",
      "Epoch: 5190/10000............. Loss: 24.5968\n",
      "Epoch: 5200/10000............. Loss: 23.7961\n",
      "Epoch: 5210/10000............. Loss: 23.7345\n",
      "Epoch: 5220/10000............. Loss: 23.7607\n",
      "Epoch: 5230/10000............. Loss: 23.5570\n",
      "Epoch: 5240/10000............. Loss: 23.4923\n",
      "Epoch: 5250/10000............. Loss: 23.4624\n",
      "Epoch: 5260/10000............. Loss: 24.0806\n",
      "Epoch: 5270/10000............. Loss: 24.3994\n",
      "Epoch: 5280/10000............. Loss: 23.3686\n",
      "Epoch: 5290/10000............. Loss: 23.7852\n",
      "Epoch: 5300/10000............. Loss: 23.7232\n",
      "Epoch: 5310/10000............. Loss: 23.5938\n",
      "Epoch: 5320/10000............. Loss: 23.6343\n",
      "Epoch: 5330/10000............. Loss: 23.7036\n",
      "Epoch: 5340/10000............. Loss: 23.8360\n",
      "Epoch: 5350/10000............. Loss: 23.6498\n",
      "Epoch: 5360/10000............. Loss: 23.5148\n",
      "Epoch: 5370/10000............. Loss: 23.6549\n",
      "Epoch: 5380/10000............. Loss: 23.4641\n",
      "Epoch: 5390/10000............. Loss: 23.8972\n",
      "Epoch: 5400/10000............. Loss: 23.3885\n",
      "Epoch: 5410/10000............. Loss: 23.5702\n",
      "Epoch: 5420/10000............. Loss: 23.4853\n",
      "Epoch: 5430/10000............. Loss: 23.4060\n",
      "Epoch: 5440/10000............. Loss: 24.2088\n",
      "Epoch: 5450/10000............. Loss: 23.5517\n",
      "Epoch: 5460/10000............. Loss: 24.1369\n",
      "Epoch: 5470/10000............. Loss: 23.8574\n",
      "Epoch: 5480/10000............. Loss: 24.2502\n",
      "Epoch: 5490/10000............. Loss: 23.6625\n",
      "Epoch: 5500/10000............. Loss: 23.7405\n",
      "Epoch: 5510/10000............. Loss: 23.7309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5520/10000............. Loss: 23.3333\n",
      "Epoch: 5530/10000............. Loss: 23.3934\n",
      "Epoch: 5540/10000............. Loss: 23.3825\n",
      "Epoch: 5550/10000............. Loss: 23.3687\n",
      "Epoch: 5560/10000............. Loss: 23.9796\n",
      "Epoch: 5570/10000............. Loss: 24.1937\n",
      "Epoch: 5580/10000............. Loss: 23.6057\n",
      "Epoch: 5590/10000............. Loss: 23.5102\n",
      "Epoch: 5600/10000............. Loss: 23.2496\n",
      "Epoch: 5610/10000............. Loss: 23.4079\n",
      "Epoch: 5620/10000............. Loss: 23.1949\n",
      "Epoch: 5630/10000............. Loss: 23.0998\n",
      "Epoch: 5640/10000............. Loss: 23.5420\n",
      "Epoch: 5650/10000............. Loss: 23.7801\n",
      "Epoch: 5660/10000............. Loss: 23.2430\n",
      "Epoch: 5670/10000............. Loss: 23.7501\n",
      "Epoch: 5680/10000............. Loss: 23.9290\n",
      "Epoch: 5690/10000............. Loss: 24.0065\n",
      "Epoch: 5700/10000............. Loss: 23.7509\n",
      "Epoch: 5710/10000............. Loss: 23.4910\n",
      "Epoch: 5720/10000............. Loss: 23.5507\n",
      "Epoch: 5730/10000............. Loss: 23.6808\n",
      "Epoch: 5740/10000............. Loss: 23.1229\n",
      "Epoch: 5750/10000............. Loss: 23.3662\n",
      "Epoch: 5760/10000............. Loss: 23.0672\n",
      "Epoch: 5770/10000............. Loss: 23.0989\n",
      "Epoch: 5780/10000............. Loss: 23.0462\n",
      "Epoch: 5790/10000............. Loss: 23.1974\n",
      "Epoch: 5800/10000............. Loss: 23.5476\n",
      "Epoch: 5810/10000............. Loss: 23.6735\n",
      "Epoch: 5820/10000............. Loss: 24.2243\n",
      "Epoch: 5830/10000............. Loss: 23.2779\n",
      "Epoch: 5840/10000............. Loss: 23.2697\n",
      "Epoch: 5850/10000............. Loss: 23.1017\n",
      "Epoch: 5860/10000............. Loss: 23.1875\n",
      "Epoch: 5870/10000............. Loss: 23.0711\n",
      "Epoch: 5880/10000............. Loss: 23.2033\n",
      "Epoch: 5890/10000............. Loss: 23.2050\n",
      "Epoch: 5900/10000............. Loss: 23.1015\n",
      "Epoch: 5910/10000............. Loss: 23.0039\n",
      "Epoch: 5920/10000............. Loss: 23.2395\n",
      "Epoch: 5930/10000............. Loss: 23.7752\n",
      "Epoch: 5940/10000............. Loss: 23.8593\n",
      "Epoch: 5950/10000............. Loss: 23.5037\n",
      "Epoch: 5960/10000............. Loss: 23.2054\n",
      "Epoch: 5970/10000............. Loss: 23.1340\n",
      "Epoch: 5980/10000............. Loss: 23.2784\n",
      "Epoch: 5990/10000............. Loss: 23.1818\n",
      "Epoch: 6000/10000............. Loss: 25.1191\n",
      "Epoch: 6010/10000............. Loss: 24.8799\n",
      "Epoch: 6020/10000............. Loss: 24.6076\n",
      "Epoch: 6030/10000............. Loss: 24.8069\n",
      "Epoch: 6040/10000............. Loss: 24.4709\n",
      "Epoch: 6050/10000............. Loss: 24.7604\n",
      "Epoch: 6060/10000............. Loss: 24.8490\n",
      "Epoch: 6070/10000............. Loss: 24.4179\n",
      "Epoch: 6080/10000............. Loss: 24.5433\n",
      "Epoch: 6090/10000............. Loss: 24.8220\n",
      "Epoch: 6100/10000............. Loss: 24.4106\n",
      "Epoch: 6110/10000............. Loss: 24.4432\n",
      "Epoch: 6120/10000............. Loss: 24.5366\n",
      "Epoch: 6130/10000............. Loss: 24.4246\n",
      "Epoch: 6140/10000............. Loss: 24.5228\n",
      "Epoch: 6150/10000............. Loss: 25.0655\n",
      "Epoch: 6160/10000............. Loss: 24.8959\n",
      "Epoch: 6170/10000............. Loss: 24.5119\n",
      "Epoch: 6180/10000............. Loss: 24.8884\n",
      "Epoch: 6190/10000............. Loss: 25.1049\n",
      "Epoch: 6200/10000............. Loss: 24.3882\n",
      "Epoch: 6210/10000............. Loss: 24.3286\n",
      "Epoch: 6220/10000............. Loss: 24.7066\n",
      "Epoch: 6230/10000............. Loss: 24.2984\n",
      "Epoch: 6240/10000............. Loss: 24.4354\n",
      "Epoch: 6250/10000............. Loss: 25.1718\n",
      "Epoch: 6260/10000............. Loss: 24.2783\n",
      "Epoch: 6270/10000............. Loss: 24.3102\n",
      "Epoch: 6280/10000............. Loss: 24.1315\n",
      "Epoch: 6290/10000............. Loss: 24.6055\n",
      "Epoch: 6300/10000............. Loss: 24.6255\n",
      "Epoch: 6310/10000............. Loss: 24.6261\n",
      "Epoch: 6320/10000............. Loss: 24.1725\n",
      "Epoch: 6330/10000............. Loss: 24.5047\n",
      "Epoch: 6340/10000............. Loss: 24.3703\n",
      "Epoch: 6350/10000............. Loss: 25.2536\n",
      "Epoch: 6360/10000............. Loss: 24.6507\n",
      "Epoch: 6370/10000............. Loss: 24.6092\n",
      "Epoch: 6380/10000............. Loss: 24.2373\n",
      "Epoch: 6390/10000............. Loss: 24.3419\n",
      "Epoch: 6400/10000............. Loss: 24.1539\n",
      "Epoch: 6410/10000............. Loss: 24.3299\n",
      "Epoch: 6420/10000............. Loss: 24.7989\n",
      "Epoch: 6430/10000............. Loss: 24.2752\n",
      "Epoch: 6440/10000............. Loss: 24.4453\n",
      "Epoch: 6450/10000............. Loss: 24.3886\n",
      "Epoch: 6460/10000............. Loss: 24.2725\n",
      "Epoch: 6470/10000............. Loss: 24.1266\n",
      "Epoch: 6480/10000............. Loss: 24.6813\n",
      "Epoch: 6490/10000............. Loss: 24.1198\n",
      "Epoch: 6500/10000............. Loss: 24.2124\n",
      "Epoch: 6510/10000............. Loss: 24.5711\n",
      "Epoch: 6520/10000............. Loss: 24.2670\n",
      "Epoch: 6530/10000............. Loss: 24.2186\n",
      "Epoch: 6540/10000............. Loss: 24.0165\n",
      "Epoch: 6550/10000............. Loss: 24.4341\n",
      "Epoch: 6560/10000............. Loss: 24.0386\n",
      "Epoch: 6570/10000............. Loss: 24.4495\n",
      "Epoch: 6580/10000............. Loss: 24.2928\n",
      "Epoch: 6590/10000............. Loss: 24.6186\n",
      "Epoch: 6600/10000............. Loss: 24.3905\n",
      "Epoch: 6610/10000............. Loss: 24.4222\n",
      "Epoch: 6620/10000............. Loss: 24.5307\n",
      "Epoch: 6630/10000............. Loss: 24.4306\n",
      "Epoch: 6640/10000............. Loss: 24.2322\n",
      "Epoch: 6650/10000............. Loss: 23.9308\n",
      "Epoch: 6660/10000............. Loss: 24.0293\n",
      "Epoch: 6670/10000............. Loss: 23.9857\n",
      "Epoch: 6680/10000............. Loss: 24.4643\n",
      "Epoch: 6690/10000............. Loss: 24.0194\n",
      "Epoch: 6700/10000............. Loss: 24.0617\n",
      "Epoch: 6710/10000............. Loss: 23.9694\n",
      "Epoch: 6720/10000............. Loss: 24.0025\n",
      "Epoch: 6730/10000............. Loss: 24.0699\n",
      "Epoch: 6740/10000............. Loss: 23.9046\n",
      "Epoch: 6750/10000............. Loss: 24.0546\n",
      "Epoch: 6760/10000............. Loss: 23.9520\n",
      "Epoch: 6770/10000............. Loss: 24.3470\n",
      "Epoch: 6780/10000............. Loss: 23.9052\n",
      "Epoch: 6790/10000............. Loss: 23.9830\n",
      "Epoch: 6800/10000............. Loss: 24.0414\n",
      "Epoch: 6810/10000............. Loss: 23.9153\n",
      "Epoch: 6820/10000............. Loss: 23.9096\n",
      "Epoch: 6830/10000............. Loss: 23.8738\n",
      "Epoch: 6840/10000............. Loss: 24.0672\n",
      "Epoch: 6850/10000............. Loss: 23.8802\n",
      "Epoch: 6860/10000............. Loss: 24.2099\n",
      "Epoch: 6870/10000............. Loss: 24.0361\n",
      "Epoch: 6880/10000............. Loss: 24.2848\n",
      "Epoch: 6890/10000............. Loss: 24.0180\n",
      "Epoch: 6900/10000............. Loss: 23.8622\n",
      "Epoch: 6910/10000............. Loss: 24.1470\n",
      "Epoch: 6920/10000............. Loss: 24.4769\n",
      "Epoch: 6930/10000............. Loss: 24.7535\n",
      "Epoch: 6940/10000............. Loss: 24.5152\n",
      "Epoch: 6950/10000............. Loss: 24.3902\n",
      "Epoch: 6960/10000............. Loss: 24.4058\n",
      "Epoch: 6970/10000............. Loss: 24.1534\n",
      "Epoch: 6980/10000............. Loss: 24.1649\n",
      "Epoch: 6990/10000............. Loss: 24.1727\n",
      "Epoch: 7000/10000............. Loss: 15.0772\n",
      "Epoch: 7010/10000............. Loss: 14.7846\n",
      "Epoch: 7020/10000............. Loss: 14.6648\n",
      "Epoch: 7030/10000............. Loss: 14.8480\n",
      "Epoch: 7040/10000............. Loss: 14.7227\n",
      "Epoch: 7050/10000............. Loss: 19.4009\n",
      "Epoch: 7060/10000............. Loss: 15.3747\n",
      "Epoch: 7070/10000............. Loss: 14.7952\n",
      "Epoch: 7080/10000............. Loss: 14.6829\n",
      "Epoch: 7090/10000............. Loss: 14.4163\n",
      "Epoch: 7100/10000............. Loss: 14.4780\n",
      "Epoch: 7110/10000............. Loss: 14.7127\n",
      "Epoch: 7120/10000............. Loss: 14.6220\n",
      "Epoch: 7130/10000............. Loss: 14.8749\n",
      "Epoch: 7140/10000............. Loss: 14.3829\n",
      "Epoch: 7150/10000............. Loss: 14.6026\n",
      "Epoch: 7160/10000............. Loss: 14.3788\n",
      "Epoch: 7170/10000............. Loss: 15.0483\n",
      "Epoch: 7180/10000............. Loss: 14.9300\n",
      "Epoch: 7190/10000............. Loss: 14.7481\n",
      "Epoch: 7200/10000............. Loss: 14.3913\n",
      "Epoch: 7210/10000............. Loss: 14.4234\n",
      "Epoch: 7220/10000............. Loss: 14.5471\n",
      "Epoch: 7230/10000............. Loss: 14.4253\n",
      "Epoch: 7240/10000............. Loss: 14.4111\n",
      "Epoch: 7250/10000............. Loss: 14.7875\n",
      "Epoch: 7260/10000............. Loss: 14.4061\n",
      "Epoch: 7270/10000............. Loss: 14.5289\n",
      "Epoch: 7280/10000............. Loss: 14.1939\n",
      "Epoch: 7290/10000............. Loss: 14.7346\n",
      "Epoch: 7300/10000............. Loss: 14.7317\n",
      "Epoch: 7310/10000............. Loss: 14.7032\n",
      "Epoch: 7320/10000............. Loss: 14.1576\n",
      "Epoch: 7330/10000............. Loss: 14.4814\n",
      "Epoch: 7340/10000............. Loss: 14.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7350/10000............. Loss: 14.7677\n",
      "Epoch: 7360/10000............. Loss: 14.3991\n",
      "Epoch: 7370/10000............. Loss: 14.3557\n",
      "Epoch: 7380/10000............. Loss: 14.0720\n",
      "Epoch: 7390/10000............. Loss: 14.6007\n",
      "Epoch: 7400/10000............. Loss: 14.7486\n",
      "Epoch: 7410/10000............. Loss: 14.2504\n",
      "Epoch: 7420/10000............. Loss: 14.2955\n",
      "Epoch: 7430/10000............. Loss: 14.1079\n",
      "Epoch: 7440/10000............. Loss: 14.6823\n",
      "Epoch: 7450/10000............. Loss: 14.4695\n",
      "Epoch: 7460/10000............. Loss: 14.1115\n",
      "Epoch: 7470/10000............. Loss: 14.0838\n",
      "Epoch: 7480/10000............. Loss: 14.2643\n",
      "Epoch: 7490/10000............. Loss: 14.1578\n",
      "Epoch: 7500/10000............. Loss: 14.1551\n",
      "Epoch: 7510/10000............. Loss: 14.1910\n",
      "Epoch: 7520/10000............. Loss: 14.4232\n",
      "Epoch: 7530/10000............. Loss: 14.1437\n",
      "Epoch: 7540/10000............. Loss: 13.9595\n",
      "Epoch: 7550/10000............. Loss: 14.1201\n",
      "Epoch: 7560/10000............. Loss: 14.3477\n",
      "Epoch: 7570/10000............. Loss: 14.2814\n",
      "Epoch: 7580/10000............. Loss: 14.1696\n",
      "Epoch: 7590/10000............. Loss: 14.2902\n"
     ]
    }
   ],
   "source": [
    "test_name = \"add-subt-div-mul\"\n",
    "\n",
    "input_seq, target_values = get_input(n_input=n_input, max_len_limit=max_len_limit, max_digit=1, alphabet=alphabet)\n",
    "target_values = target_values.to(device)\n",
    "\n",
    "bets_model = None\n",
    "best_loss = 99999999\n",
    "\n",
    "time = datetime.now()\n",
    "time = str(time.month) + \"-\" + str(time.day) + \"-\" + str(time.hour) + \"-\" + str(time.minute)\n",
    "\n",
    "#dir_name = \"/home/sadullah/calculator/model_logs/{}_{}\".format(test_name, time)\n",
    "#os.mkdir(dir_name)\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        input_seq, target_values = get_input(n_input=n_input, max_len_limit=max_len_limit, max_digit=1, alphabet=alphabet)\n",
    "        target_values = target_values.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    input_seq = input_seq.to(device)\n",
    "    output = model(input_seq)\n",
    "    loss = loss_fn(output, target_values)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        \n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model\n",
    "            time = datetime.now()\n",
    "            time = str(time.month) + \"-\" + str(time.day) + \"-\" + str(time.hour) + \"-\" + str(time.minute)\n",
    "            #torch.save(model.state_dict(),(dir_name+'/{0}_{1:.4f}.pth').format(epoch,loss))\n",
    "        \n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, seq):\n",
    "    while len(seq) < max_len_limit: seq += ' '\n",
    "    one_hot_input = __create_one_hot_seq(alphabet, max_len_limit, [seq])\n",
    "    input_seq = torch.FloatTensor(one_hot_input).permute(1,0,2)\n",
    "    input_seq = input_seq.to(device)\n",
    "    output = model(input_seq)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '9*9/9+9'\n",
    "y = '5/3+5*2'\n",
    "z = '2*3/5-7'\n",
    "r = '9/3*5+2'\n",
    "a = predict(model, x).data\n",
    "b = predict(model, y).data\n",
    "c = predict(model, z).data\n",
    "d = predict(model, r).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
